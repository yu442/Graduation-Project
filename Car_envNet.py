import copy
import random
import numpy as np
import random
'''
å®šä¹‰Stateï¼ŒActionï¼ŒReward
Stateä¸º[X,V],Actionä¸ºåˆ¹è½¦å’Œè¸©æ²¹é—¨ï¼ŒRewardä¸º J = -et Q e
Xt+1=Xt+Vt*ğŸ”ºt
Vt+1=Vt+At*ğŸ”ºt
'''
class Car():
    def __init__(self):
        # self.action_space = [[1], [-1], [0]]
        # self.n_actions = len(self.action_space)
        self.n_features = 2
        self.observation = [0, 0]
        # æœŸæœ›é—´è·
        self.target = 10
        # å‰è½¦çŠ¶æ€
        self.pl = 0
        self.vl = 0
        # å½“å‰è½¦çŠ¶æ€
        self.pm = 0
        self.vm = 0
        # ä½ç½®å‚æ•°å’Œé€Ÿåº¦å‚æ•°
        self.pq = 5
        self.vq = 10
        # ä»¿çœŸæ­¥é•¿
        self.t = 1
        # è®¾ç½®æœ€å¤§é€Ÿåº¦å’Œæœ€å°é€Ÿåº¦
        self.max = 15
        self.min = 5
        # æ­¥æ•°
        self.st = 0
    # åˆ›å»ºç¯å¢ƒ
    # åˆå§‹åŒ–æ¯è¾†è½¦çš„é€Ÿåº¦
    # vm = [10, random.randint(5, 15), random.randint(5, 15), random.randint(5, 15)]
    # è·å–çŠ¶æ€S
    def reset(self,
              pl,
              pm,
              vl,
    ):
        self.st = 0
        # è®¾ç½®æ¯è¾†è½¦çš„ä½ç½®,æ¯è¾†è½¦é—´è·100m
        self.pl = pl
        self.pm = pm
        # åˆå§‹åŒ–æ¯è¾†è½¦çš„é€Ÿåº¦
        self.vl = vl
        # self.vm = random.randint(5, 15)
        self.vm = 6
        self.max = 15
        self.observation[0] = self.pl - self.pm
        self.observation[1] = self.vl - self.vm
        return self.observation

    # åˆ·æ–°ç¯å¢ƒ
    def render(self,v,p):
        self.vl = v
        self.pl = p
        self.observation[0] = self.pl - self.pm
        self.observation[1] = self.vl - self.vm
        return self.observation

    # åˆ¤æ–­æ˜¯å¦å‘ç”Ÿç¢°æ’
    def iscollsion(self,s):

        if(s[0] <= 0):
            return True
        return False

    # åŠ¨ä½œçš„æ‰§è¡Œæ•ˆæœ
    def step(self,action):
        a = action[0]
        self.st += 1
        reward = 0
        # s = copy.deepcopy(self.observation)
        s = self.observation
        if self.vm + a > self.max:
            self.vm = self.max
            self.pm += self.vm
            self.pl += self.vl
        elif self.vm + a < self.min:
            self.vm = self.min
            self.pm += self.vm
            self.pl += self.vl
        else:
            self.vm += a
            self.pm += self.vm
            self.pl += self.vl
        s[0] = self.pl - self.pm
        s[1] = self.vl - self.vm

        if self.iscollsion(s) == True:
            reward += -1000
            done = True
        else:

            reward += -(self.pq * (s[0]) ** 2 + self.vq * (s[1]) ** 2)/100
            done = False
        return s,reward,done





import copy
import random
import numpy as np
import random
'''
å®šä¹‰Stateï¼ŒActionï¼ŒReward
Stateä¸º[X,V],Actionä¸ºåˆ¹è½¦å’Œè¸©æ²¹é—¨ï¼ŒRewardä¸º J = -et Q e
Xt+1=Xt+Vt*ğŸ”ºt
Vt+1=Vt+At*ğŸ”ºt
'''
class Car():
    def __init__(self):
        # self.action_space = [[1], [-1], [0]]
        # self.n_actions = len(self.action_space)
        self.n_features = 2
        self.observation = [0, 0]
        # æœŸæœ›é—´è·
        self.target = 10
        # å‰è½¦çŠ¶æ€
        self.pl = 0
        self.vl = 0
        # å½“å‰è½¦çŠ¶æ€
        self.pm = 0
        self.vm = 0
        # ä½ç½®å‚æ•°å’Œé€Ÿåº¦å‚æ•°
        self.pq = 5
        self.vq = 10
        # ä»¿çœŸæ­¥é•¿
        self.t = 1
        # è®¾ç½®æœ€å¤§é€Ÿåº¦å’Œæœ€å°é€Ÿåº¦
        self.max = 15
        self.min = 5
        # æ­¥æ•°
        self.st = 0
    # åˆ›å»ºç¯å¢ƒ
    # åˆå§‹åŒ–æ¯è¾†è½¦çš„é€Ÿåº¦
    # vm = [10, random.randint(5, 15), random.randint(5, 15), random.randint(5, 15)]
    # è·å–çŠ¶æ€S
    def reset(self,
              pl,
              pm,
              vl,
    ):
        self.st = 0
        # è®¾ç½®æ¯è¾†è½¦çš„ä½ç½®,æ¯è¾†è½¦é—´è·100m
        self.pl = pl
        self.pm = pm
        # åˆå§‹åŒ–æ¯è¾†è½¦çš„é€Ÿåº¦
        self.vl = vl
        # self.vm = random.randint(5, 15)
        self.vm = 6
        self.max = 15
        self.observation[0] = self.pl - self.pm
        self.observation[1] = self.vl - self.vm
        return self.observation

    # åˆ·æ–°ç¯å¢ƒ
    def render(self,v,p):
        self.vl = v
        self.pl = p
        self.observation[0] = self.pl - self.pm
        self.observation[1] = self.vl - self.vm
        return self.observation

    # åˆ¤æ–­æ˜¯å¦å‘ç”Ÿç¢°æ’
    def iscollsion(self,s):

        if(s[0] <= 0):
            return True
        return False

    # åŠ¨ä½œçš„æ‰§è¡Œæ•ˆæœ
    def step(self,action):
        a = action[0]
        self.st += 1
        reward = 0
        # s = copy.deepcopy(self.observation)
        s = self.observation
        if self.vm + a > self.max:
            self.vm = self.max
            self.pm += self.vm
            self.pl += self.vl
        elif self.vm + a < self.min:
            self.vm = self.min
            self.pm += self.vm
            self.pl += self.vl
        else:
            self.vm += a
            self.pm += self.vm
            self.pl += self.vl
        s[0] = self.pl - self.pm
        s[1] = self.vl - self.vm

        if self.iscollsion(s) == True:
            reward += -1000
            done = True
        else:

            reward += -(self.pq * (s[0]) ** 2 + self.vq * (s[1]) ** 2)/100
            done = False
        return s,reward,done





